{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in 'indu' dataframe:\n",
      "Time       datetime64[ns]\n",
      "indu_Q1           float64\n",
      "indu_Q2           float64\n",
      "indu_Q3           float64\n",
      "indu_Q4           float64\n",
      "indu_Q5           float64\n",
      "indu_Q7           float64\n",
      "dtype: object\n",
      "\n",
      "Data types in 'cons' dataframe:\n",
      "Time        datetime64[ns]\n",
      "cons_Q1            float64\n",
      "cons_Q2            float64\n",
      "cons_Q3            float64\n",
      "cons_Q4            float64\n",
      "cons_Q5            float64\n",
      "cons_Q6            float64\n",
      "cons_Q7            float64\n",
      "cons_Q8            float64\n",
      "cons_Q9            float64\n",
      "cons_Q10           float64\n",
      "cons_Q11           float64\n",
      "cons_Q12           float64\n",
      "dtype: object\n",
      "\n",
      "Data types in 'gdp' dataframe:\n",
      "Time     datetime64[ns]\n",
      "Value           float64\n",
      "dtype: object\n",
      "indu_Q1           float64\n",
      "indu_Q2           float64\n",
      "indu_Q3           float64\n",
      "indu_Q4           float64\n",
      "indu_Q5           float64\n",
      "indu_Q7           float64\n",
      "Time       datetime64[ns]\n",
      "dtype: object\n",
      "cons_Q1            float64\n",
      "cons_Q2            float64\n",
      "cons_Q3            float64\n",
      "cons_Q4            float64\n",
      "cons_Q5            float64\n",
      "cons_Q6            float64\n",
      "cons_Q7            float64\n",
      "cons_Q8            float64\n",
      "cons_Q9            float64\n",
      "cons_Q10           float64\n",
      "cons_Q11           float64\n",
      "cons_Q12           float64\n",
      "Time        datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Run the stored data from the Data_Preparation.ipynb\n",
    "%run ..//Data_Preparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing data\n",
    "indu_train = indu[(indu['Time'] >= '1990-01-01') & (indu['Time'] < '2020-01-01')]\n",
    "cons_train = cons[(cons['Time'] >= '1990-01-01') & (cons['Time'] < '2020-01-01')]\n",
    "gdp_train = gdp[(gdp['Time'] >= '1990-01-01') & (gdp['Time'] < '2020-01-01')]\n",
    "\n",
    "indu_test = indu[(indu['Time'] >= '2020-01-01') & (indu['Time'] < '2024-01-01')]\n",
    "cons_test = cons[(cons['Time'] >= '2020-01-01') & (cons['Time'] < '2024-01-01')]\n",
    "gdp_test = gdp[(gdp['Time'] >= '2020-01-01') & (gdp['Time'] < '2024-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Mistral Large Language Model\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:11<00:00, 65.95s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting relevant columns for training\n",
    "gdp_train_list = gdp_train[['Time', 'Value']].values.tolist()\n",
    "\n",
    "# Inserting gdp_train into the prompt string\n",
    "prompt = f\"\"\"\n",
    "You are a time series forecasting model designed to predict the Danish GDP based on historical data. \n",
    "Your task is to forecast the GDP from 2020Q1 until 2023Q4, using the provided GDP training data.\n",
    "\n",
    "The provided GDP training data is as follows:\n",
    "{gdp_train_list}\n",
    "\n",
    "Please analyze the provided data, which represents the GDP values over time, and generate predictions for the GDP for the specified timeframe. Your output should be a list of predicted GDP values for each quarter from 2020Q1 to 2023Q4.\n",
    "\n",
    "Note: Your predictions should consider the underlying patterns in the data and provide realistic forecasts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the prompt\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate predictions\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Decode and print the output\n",
    "predicted_gdp = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(predicted_gdp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)\n",
    "print(inputs)\n",
    "print(output)\n",
    "print(output_decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
